{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location Used: Murfreesboro, TN\n",
    "\n",
    "https://www.openstreetmap.org/relation/197137 \n",
    "\n",
    "I chose the map of Murfreesboro because it is the city where I live. It is in Tennessee and could be considered a suburb of Nashville. It is the geographic center of Tennessee and was formerly the state capital. It is currently one of the fastest growing cities in the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By pulling out all the street types (for example street, way, road) in the data set I see that there are a few that have multiple spellings and abbreviations. Boulevard is spelled out but also abbreviated as Blvd. The same is true for court, drive, parkway, road, and street. There also appears to be a zip code (postal code) entered as a street type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also pulled out the zipcodes in the OSM data. These are tagged as postcode in the file. I found that there were a couple that were not formatted correctly. They were longer than 5 digits. Also, there were fourteen different zipcodes in the file. According to the United States Postal Service website there are only seven zipcodes in Murfreesboro, TN. (https://tools.usps.com/zip-code-lookup.htm?bycitystate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the modules that will be needed\n",
    "import csv \n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#112: 2\n",
      "37128: 1\n",
      "Avenue: 3\n",
      "B220: 1\n",
      "Blvd: 1\n",
      "Boulevard: 84\n",
      "Circle: 1\n",
      "Court: 73\n",
      "Crossing: 1\n",
      "Ct: 1\n",
      "Dr: 1\n",
      "Drive: 189\n",
      "East: 2\n",
      "Fork: 1\n",
      "Highway: 12\n",
      "Lane: 144\n",
      "Parkway: 30\n",
      "Pass: 2\n",
      "Pike: 26\n",
      "Pkwy: 2\n",
      "Place: 16\n",
      "Rd: 7\n",
      "Road: 69\n",
      "Row: 1\n",
      "Square: 1\n",
      "St: 1\n",
      "Street: 38\n",
      "Terrace: 2\n",
      "Trace: 1\n",
      "Trail: 1\n",
      "Way: 5\n",
      "West: 1\n"
     ]
    }
   ],
   "source": [
    "#The different street types and how often they appear in the data\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "osm_file = open(\"map.xml\", \"r\")\n",
    "\n",
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(int)\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "\n",
    "        street_types[street_type] += 1\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v) \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit():\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if is_street_name(elem):\n",
    "            audit_street_type(street_types, elem.attrib['v'])    \n",
    "    print_sorted_dict(street_types)    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    audit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the zipcodes in the Murfreesboro, TN OSM file: set(['37037', '37027', '37167', '37013', '37014', '37086', '37130', '37128', '37129', '37135', '37067', '37127', '37153', '37211'])\n",
      "10 of these zipcodes are outside of Murfreesboro, TN\n",
      "These are the zipcodes that did not meet the standard format ['37132-0001', '37132-0001']\n"
     ]
    }
   ],
   "source": [
    "#Postalcodes/Zipcodes audit\n",
    "mboro_pcodes = 'map.xml'\n",
    "\n",
    "#sorting the properly and improperly formatted zipcodes into their own lists\n",
    "def audit_postal_code(error_codes, postal_codes, zipcode): \n",
    "    if zipcode.isdigit() == False:\n",
    "        error_codes.append(zipcode)\n",
    "    elif len(zipcode) != 5:\n",
    "        error_codes.append(zipcode)\n",
    "    else:\n",
    "        postal_codes.update([zipcode])\n",
    "\n",
    "#defining where the zipcodes can be pulled from in the xml data\n",
    "#they are called postcodes in the OSM file, not zipcodes\n",
    "def is_postal_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\" or elem.attrib['k'] == \"postal_code\")\n",
    "\n",
    "#opening the OSM file and pulling the zipcodes out to sort them into an error list and correct list\n",
    "def audit_post(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    error_codes = []\n",
    "    postal_codes = set([])\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postal_code(tag):\n",
    "                    audit_postal_code(error_codes, postal_codes, tag.attrib[\"v\"]) \n",
    "    return error_codes, postal_codes\n",
    "\n",
    "error_list, postcode_list = audit_post(mboro_pcodes)\n",
    "\n",
    "# List of Murfreesboro, TN zip codes\n",
    "murfreesboro_postalcodes = [ '37127', '37128', '37129', '37130', '37131', \n",
    "                        '37132', '37133']\n",
    "\n",
    "# number of zip codes in the osm file that are outside of Murfreesboro, TN\n",
    "count = 0\n",
    "for i in postcode_list:\n",
    "    if i not in murfreesboro_postalcodes:\n",
    "        count += 1\n",
    "\n",
    "print \"These are the zipcodes in the Murfreesboro, TN OSM file:\", postcode_list\n",
    "print count, \"of these zipcodes are outside of Murfreesboro, TN\"\n",
    "print \"These are the zipcodes that did not meet the standard format\", error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Shaping the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows the code/processes for cleaning the data and then shaping it to be inserted into a SQL database. \n",
    "\n",
    "For the addresses I am updating the abbreviations of the street types to full words. I did find a zip code and what appeared to be an apartment number in the street type data, but I did not clean this data. For the zip codes I am updating the ones that did not meet the standard 5 digit format. There were also several zipcodes that were outside the Murfreesboro area according to the USPS website that I did not clean. The additonal address and zipcode issues should be addressed and cleaned, but this would involve the type of research and cost that is beyond the scope of this project. A suggestion for cleaning this data would include using the USPS services for cleaning address lists (https://pe.usps.com/BusinessMail101?ViewName=CheckTheAddresses). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import schema\n",
    "\n",
    "#From OSM of Murfreesboro, TN, changed to XML\n",
    "MAP_FILE = \"map.xml\"\n",
    "\n",
    "#Regular expression to help in the search through the XML file for the street types (such as drive, dr, ave...)  \n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# These are the correct street types, this list is used for checking the street types \n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Road\", \n",
    "            \"Parkway\", \"Plaza\", \"Broadway\", \"Circle\", \"Driveway\", \"Highway\", \"Park\", \"Lane\"]\n",
    "\n",
    "# This dictionary is used to correct the street types from their \n",
    "#incorrect entry in the map.xml file to the correct type\n",
    "mapping = {\"St\": \"Street\",\n",
    "           \"st\": \"Street\",\n",
    "           \"Street.\": \"Street\", \n",
    "           \"street\": \"Street\", \n",
    "           \"ST\": \"Street\",\n",
    "           \"Blvd\":\"Boulevard\",\n",
    "           \"Ave\": \"Avenue\", \n",
    "           \"Pkwy\": \"Parkway\", \n",
    "           \"Ct\": \"Court\",  \n",
    "           \"Dr\": \"Drive\", \n",
    "           \"Rd\": \"Road\", \n",
    "           \"Hwy\": \"Highway\"}\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the\n",
    "# sql table schema\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "#looks for the incorrect street types in the street names by comparing them to the \"expected\" list\n",
    "#and then puts them in a list called street_types\n",
    "#uses the regular expression \"street_type_re\" defined prevously to locate the street type within the street name\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "#finds the street names in the map.xml file\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#executes the audit_street_type and is_street_name functions to fill the street_types dictionary\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "#fixes the street type in the street name\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        for i in mapping:\n",
    "            if i == m.group():\n",
    "                name = re.sub(street_type_re, mapping[i], name)\n",
    "    return name\n",
    "\n",
    "#finds the zip codes in the address \n",
    "def is_postcode(elem): \n",
    "    return (elem.attrib['k'] == \"addr:postcode\" or elem.attrib['k'] == \"postal_code\")\n",
    "\n",
    "#creates a list of zipcodes\n",
    "def audit_postcode(postcodes, postcode):\n",
    "    postcodes[postcode].add(postcode)\n",
    "    return postcodes\n",
    "\n",
    "#updates/cleans the zipcodes \n",
    "def update_postcode(postcode):\n",
    "    if re.findall(r'^\\d{5}$', postcode): # 5 digits\n",
    "        valid_postcode = postcode\n",
    "        return valid_postcode  \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Shape each element into several data structures\n",
    "#Clean and shape node or way XML element to Python dict\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \n",
    "    node_attribs = {} \n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for i in NODE_FIELDS:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):  \n",
    "            problem = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if not problem:\n",
    "                node_tag = {} \n",
    "                node_tag['id'] = element.attrib['id'] \n",
    "                node_tag['value'] = tag.attrib['v']  \n",
    "\n",
    "                match = LOWER_COLON.search(tag.attrib['k'])\n",
    "                if not match:\n",
    "                    node_tag['type'] = 'regular'\n",
    "                    node_tag['key'] = tag.attrib['k']\n",
    "                else:\n",
    "                    bef_colon = re.findall('^(.+):', tag.attrib['k'])\n",
    "                    aft_colon = re.findall('^[a-z|_]+:(.+)', tag.attrib['k'])\n",
    "                    node_tag['type'] = bef_colon[0]\n",
    "                    node_tag['key'] = aft_colon[0]\n",
    "                    if node_tag['type'] == \"addr\" and node_tag['key'] == \"street\":\n",
    "                        # update street name\n",
    "                        node_tag['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                    elif node_tag['type'] == \"addr\" and node_tag['key'] == \"postcode\":\n",
    "                        # update post code\n",
    "                        node_tag['value'] = update_postcode(tag.attrib['v']) \n",
    "            tags.append(node_tag)\n",
    "        \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for i in WAY_FIELDS:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            problem = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if not problem:\n",
    "                way_tag = {}\n",
    "                way_tag['id'] = element.attrib['id'] \n",
    "                way_tag['value'] = tag.attrib['v']\n",
    "                match = LOWER_COLON.search(tag.attrib['k'])\n",
    "                if not match:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = tag.attrib['k']\n",
    "                else:\n",
    "                    bef_colon = re.findall('^(.+?):+[a-z]', tag.attrib['k'])\n",
    "                    aft_colon = re.findall('^[a-z|_]+:(.+)', tag.attrib['k'])\n",
    "\n",
    "                    way_tag['type'] = bef_colon[0]\n",
    "                    way_tag['key'] = aft_colon[0]\n",
    "                    if way_tag['type'] == \"addr\" and way_tag['key'] == \"street\":\n",
    "                        way_tag['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                    elif way_tag['type'] == \"addr\" and way_tag['key'] == \"postcode\":\n",
    "                        way_tag['value'] = update_postcode(tag.attrib['v']) \n",
    "            tags.append(way_tag)\n",
    "        position = 0\n",
    "        for tag in element.iter(\"nd\"):  \n",
    "            nd = {}\n",
    "            nd['id'] = element.attrib['id'] \n",
    "            nd['node_id'] = tag.attrib['ref'] \n",
    "            nd['position'] = position  \n",
    "            position += 1\n",
    "            \n",
    "            way_nodes.append(nd)\n",
    "    \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "#Yield element if it is the right type of tag\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "#Raise ValidationError if element does not match schema\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "#Extend csv.DictWriter to handle Unicode input\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "#Iteratively process each XML element and write to csv(s)\n",
    "def process_map(file_in, validate):\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_map(MAP_FILE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for establishing a connection to the database I created in MySQL using the OSM data. I used the csv files created in the process above to create the database. To be able to run and show my SQL queries I had to include this to create the connection between the MySQL database and my Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x118f80850>\n"
     ]
    }
   ],
   "source": [
    "#connect to MySQL\n",
    "import mysql.connector\n",
    "#db = mysql.connector.connect(MySQL_DataWrangle_OSM)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd=\"****\",\n",
    "  database=\"default_schema\",\n",
    "  use_pure=True\n",
    ")\n",
    "\n",
    "#confirm the connection\n",
    "print(mydb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code and results that show the size of each csv file that was imported into the database. They were created during the cleaning and shaping process. The size is shown in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Size (In bytes) of 'nodes.csv':\", 40649303)\n",
      "(\"Size (In bytes) of 'ways.csv':\", 3137016)\n",
      "(\"Size (In bytes) of 'nodes_tags.csv':\", 784549)\n",
      "(\"Size (In bytes) of 'ways_tags.csv':\", 4831559)\n",
      "(\"Size (In bytes) of 'ways_nodes.csv':\", 13339926)\n"
     ]
    }
   ],
   "source": [
    "#links to the csv files\n",
    "nodes_csv = 'nodes.csv'\n",
    "ways_csv = 'ways.csv'\n",
    "nodestags_csv = 'nodes_tags.csv'\n",
    "waystags_csv = 'ways_tags.csv'\n",
    "waysnodes_csv = 'ways_nodes.csv'\n",
    "\n",
    "# Get the size (in bytes) of specified path  \n",
    "size_nodes = os.path.getsize(nodes_csv) \n",
    "size_ways = os.path.getsize(ways_csv) \n",
    "size_nodestags = os.path.getsize(nodestags_csv) \n",
    "size_waystags = os.path.getsize(waystags_csv) \n",
    "size_waysnodes = os.path.getsize(waysnodes_csv) \n",
    "  \n",
    "# Print the size (in bytes) of specified path  \n",
    "print(\"Size (In bytes) of '%s':\" %nodes_csv, size_nodes)\n",
    "print(\"Size (In bytes) of '%s':\" %ways_csv, size_ways)\n",
    "print(\"Size (In bytes) of '%s':\" %nodestags_csv, size_nodestags)\n",
    "print(\"Size (In bytes) of '%s':\" %waystags_csv, size_waystags)\n",
    "print(\"Size (In bytes) of '%s':\" %waysnodes_csv, size_waysnodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 687 unique users in the nodes and ways files for the Murfreesboro, TN OSM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of unique users in the nodes and ways files:', [(687,)])\n"
     ]
    }
   ],
   "source": [
    "#code for number of unique users\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print('The number of unique users in the nodes and ways files:', myresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 67,085 nodes and 51,792 ways in my OSM data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of nodes:', (67085,))\n"
     ]
    }
   ],
   "source": [
    "#code to show the number of nodes\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"SELECT COUNT(*) FROM nodes\"\n",
    "mycursor.execute(sql)\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "for x in myresult:\n",
    "  print('The number of nodes is:', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of ways is:', (51792,))\n"
     ]
    }
   ],
   "source": [
    "#code to show the number of ways\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"SELECT COUNT(*) FROM ways\"\n",
    "mycursor.execute(sql)\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "for x in myresult:\n",
    "  print('The number of ways is:', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since moving to Murfreesboro several years ago I have noticed that there are always small, personal planes buzzing around. Also, Middle Tennessee State University, a large college located in Murfreesboro, has one of the largest collegiate aviation programs in the country. So I was curious about what the OSM data would say regarding airports and landing strips in the area. I used two queries to count how many aerodomes were in the nodes_tags and ways_tags files. According to the OSM Wiki an aeroway \"describes the fixed physical infrastructure associated with air travel and space flight, including airports, runways, helipads, and terminal buildings\" and an aerodome includes airports, aerodromes, airfields, and landing strips. The queries returned 15 instances. This did not surprise me due to the enthusiasm for flying I have observed in the area. \n",
    "\n",
    "OSM Wiki: https://wiki.openstreetmap.org/wiki/Aeroways\n",
    "\n",
    "MTSU Aerospace program: https://www.mtsu.edu/aerospace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'aerodrome', 13)]\n"
     ]
    }
   ],
   "source": [
    "#getting the aeroways - aerodromes from the nodes_tags table\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='aerodrome') i ON nodes_tags.id=i.id WHERE nodes_tags.key='aeroway' GROUP BY nodes_tags.value ORDER BY num DESC\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print (myresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'aerodrome', 2)]\n"
     ]
    }
   ],
   "source": [
    "#getting the aeroways - aerodromes from the ways_tags table\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT ways_tags.value, COUNT(*) as num FROM ways_tags JOIN (SELECT DISTINCT(id) FROM ways_tags WHERE value='aerodrome') i ON ways_tags.id=i.id WHERE ways_tags.key='aeroway' GROUP BY ways_tags.value ORDER BY num DESC\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print (myresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My family has an active, two year old labrador retriever. So I was curious if there were any entries in the OSM data for my area related to dogs. First I ran a query to find any dog parks. These can be found in the nodes_tags and ways_tags tables, in the key column under leasure and in the value column under dag_parks. My query found 3 dog parks. Then I wanted to see if there were any pet stores. First I queried the same two tables using the key column looking for the different types if shops. The query included pet as a shop. Then I queried the tables for any instance of pet and found two pet shops. \n",
    "\n",
    "On a national level the ownership of dogs and spending on pets is increasing. There also seems to be an change in the way people consider dogs. More people are starting to think of them as a family member and less like \"just a pet/dog\". A good axample of this change in thinking is the new law making animal cruelty a federal crime. I was suprised there weren't more dog parks and pet stores in Murfreesboro. I would guess that it's not as much as people not changing thier opinions on dogs, but more about the size of Murfreesboro. It is a fast growing city but it still only has a population of around 141,000 people. \n",
    "\n",
    "\n",
    "https://www.americanpetproducts.org/press_industrytrends.asp\n",
    "\n",
    "https://www.americanpetproducts.org/press_releasedetail.asp?id=191\n",
    "\n",
    "https://www.npr.org/2019/11/25/782842651/trump-signs-law-making-cruelty-to-animals-a-federal-crime\n",
    "\n",
    "https://www.census.gov/quickfacts/fact/table/murfreesborocitytennessee/PST045218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'dog_park',), (u'dog_park',), (u'dog_park',)]\n"
     ]
    }
   ],
   "source": [
    "#code to return dog_parks from ways_tags and node_tages tables\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT value FROM ways_tags WHERE value='dog_park' UNION ALL SELECT value FROM nodes_tags WHERE value='dog_park'\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print (myresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'supermarket',), (u'chemist',), (u'mall',), (u'doityourself',), (u'craft',), (u'mobile_phone',), (u'convenience',), (u'jewelry',), (u'shoes',), (u'car_repair',), (u'wholesale',), (u'department_store',), (u'pet',), (u'tyres',), (u'car',), (u'ticket',), (u'yes',), (u'houseware',), (u'country_store',), (u'alcohol',), (u'storage_rental',), (u'variety_store',), (u'car_parts',), (u'fabric',), (u'pastry',), (u'antiques',), (u'motorcycle',), (u'hardware',), (u'shipping',), (u'hairdresser',), (u'nutrition_supplements',), (u'*',), (u'gift',), (u'furniture',), (u'beauty',), (u'stationery',), (u'clothes',), (u'toys',), (u'laundry',)]\n"
     ]
    }
   ],
   "source": [
    "#code to list the types of shops in the tables\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT ways_tags.value FROM ways_tags WHERE ways_tags.key='shop' UNION SELECT nodes_tags.value FROM nodes_tags WHERE nodes_tags.key='shop'\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print (myresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pet',), (u'pet',)]\n"
     ]
    }
   ],
   "source": [
    "#code to show each instance of pet in the ways_tag and nodes-tags tables\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"SELECT ways_tags.value FROM ways_tags WHERE ways_tags.value='pet' UNION ALL SELECT nodes_tags.value FROM nodes_tags WHERE nodes_tags.value='pet'\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "print (myresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the db connection\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to be fairly clean but I do wonder about how current it is. Murfreesboro has experienced explosive growth over the past few years which has created a boom in construction in both housing and commercial projects (see the two links below). This also means many new roads, schools and other community projects. This is a lot of change in a short amount of time. Since OSM is a community project that has many collaborators at any given time, there is no guarantee as to when and how often the data for a specific area is updated. A suggestion to help with this issue would be to recruit or advertise to people who are interested in data analytics, data analysis, coding, cartography or geodata.\n",
    "\n",
    "https://www.dnj.com/story/news/local/2019/02/22/why-murfreesboro-growing-so-fast-tennessee-capital-name-ask-google/2927769002/\n",
    "\n",
    "https://www.wkrn.com/news/murfreesboros-growth-attracts-big-companies-fuels-area-economy/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
